{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Sentiment Analysis LSTM Using Noisy Crowd Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a version of the [crowdsourcing tutorial that uses PySpark](https://github.com/HazyResearch/snorkel/blob/master/tutorials/crowdsourcing/Crowdsourced_Sentiment_Analysis.ipynb) using Pandas instead of SparkSQL.\n",
    "\n",
    "In this tutorial, we'll provide a simple walkthrough of how to use Snorkel to resolve conflicts in a noisy crowdsourced dataset for a sentiment analysis task, and then use these denoised labels to train an LSTM sentiment analysis model which can be applied to new, unseen data to automatically make predictions!\n",
    "\n",
    "1. Creating basic Snorkel objects: `Candidates`, `Contexts`, and `Labels`\n",
    "2. Training the `GenerativeModel` to resolve labeling conflicts\n",
    "3. Training a simple LSTM sentiment analysis model, which can then be used on new, unseen data!\n",
    "\n",
    "Note that this is a simple tutorial meant to give an overview of the mechanics of using Snorkel-- we'll note places where more careful fine-tuning could be done!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Detail: Weather Sentiments in Tweets\n",
    "\n",
    "In this tutorial we focus on the [Weather sentiment](https://www.crowdflower.com/data/weather-sentiment/) task from [Crowdflower](https://www.crowdflower.com/).\n",
    "\n",
    "In this task, contributors were asked to grade the sentiment of a particular tweet relating to the weather. Contributors could choose among the following categories:\n",
    "1. Positive\n",
    "2. Negative\n",
    "3. I can't tell\n",
    "4. Neutral / author is just sharing information\n",
    "5. Tweet not related to weather condition\n",
    "\n",
    "The catch is that 20 contributors graded each tweet. Thus, in many cases contributors assigned conflicting sentiment labels to the same tweet. \n",
    "\n",
    "The task comes with two data files (to be found in the `data` directory of the tutorial:\n",
    "1. [weather-non-agg-DFE.csv](data/weather-non-agg-DFE.csv) contains the raw contributor answers for each of the 1,000 tweets.\n",
    "2. [weather-evaluated-agg-DFE.csv](data/weather-evaluated-agg-DFE.csv) contains gold sentiment labels by trusted workers for each of the 1,000 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocessing - Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the raw data for our crowdsourcing task (stored in a local csv file) into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Raw Crowdsourcing Data\n",
    "raw_crowd_answers = pd.read_csv(\"data/weather-non-agg-DFE.csv\")\n",
    "\n",
    "# Load Groundtruth Crowdsourcing Data\n",
    "gold_crowd_answers = pd.read_csv(\"data/weather-evaluated-agg-DFE.csv\")\n",
    "# Filter out low-confidence answers\n",
    "gold_answers = gold_crowd_answers[['tweet_id', 'sentiment', 'tweet_body']][(gold_crowd_answers.correct_category == 'Yes') & (gold_crowd_answers.correct_category_conf == 1)] \n",
    "\n",
    "# Keep Only the Tweets with Available Groundtruth\n",
    "candidate_labeled_tweets = raw_crowd_answers.join(gold_answers.set_index('tweet_id',drop=False),on=['tweet_id'],lsuffix='.raw',rsuffix='.gold',how='inner')\n",
    "candidate_labeled_tweets = candidate_labeled_tweets[['tweet_id.raw','tweet_body.raw','worker_id','emotion']]\n",
    "candidate_labeled_tweets.columns = ['tweet_id','tweet_body','worker_id','emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, contributors can provide conflicting labels for the same tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_body</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>79195142</td>\n",
       "      <td>G'morning, Sunshine: 60s and partly sunny? OK!</td>\n",
       "      <td>6332651</td>\n",
       "      <td>Neutral / author is just sharing information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>79196060</td>\n",
       "      <td>I woke up to a beautiful ball of red coming ov...</td>\n",
       "      <td>6332651</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>80054061</td>\n",
       "      <td>@mention It's supposed to go up to 70 today. S...</td>\n",
       "      <td>6332651</td>\n",
       "      <td>Neutral / author is just sharing information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>80056390</td>\n",
       "      <td>@mention that was the effect I was hoping for ...</td>\n",
       "      <td>6332651</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>81215474</td>\n",
       "      <td>Dateline: Elkhart Lake, WI - It's cloudy, chil...</td>\n",
       "      <td>6332651</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id                                         tweet_body  worker_id  \\\n",
       "1527  79195142     G'morning, Sunshine: 60s and partly sunny? OK!    6332651   \n",
       "1512  79196060  I woke up to a beautiful ball of red coming ov...    6332651   \n",
       "1517  80054061  @mention It's supposed to go up to 70 today. S...    6332651   \n",
       "1546  80056390  @mention that was the effect I was hoping for ...    6332651   \n",
       "1526  81215474  Dateline: Elkhart Lake, WI - It's cloudy, chil...    6332651   \n",
       "\n",
       "                                           emotion  \n",
       "1527  Neutral / author is just sharing information  \n",
       "1512                                      Positive  \n",
       "1517  Neutral / author is just sharing information  \n",
       "1546                                      Negative  \n",
       "1526                                      Positive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_labeled_tweets.sort_values(['worker_id','tweet_id']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generating Snorkel Objects\n",
    "\n",
    "### `Candidates`\n",
    "\n",
    "`Candidates` are the core objects in Snorkel representing objects to be classified. We'll use a helper function to create a custom `Candidate` sub-class, `Tweet`, with values representing the possible labels that it can be classified with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "values = list(candidate_labeled_tweets.emotion.unique())\n",
    "\n",
    "Tweet = candidate_subclass('Tweet', ['tweet'], values=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Contexts`\n",
    "\n",
    "All `Candidate` objects point to one or more `Context` objects, which represent the raw data that they are rooted in. In this case, our candidates will each point to a single `Context` object representing the raw text of the tweet.\n",
    "\n",
    "Once we have defined the `Context` for each `Candidate`, we can commit them to the database. Note that we also split into two sets while doing this:\n",
    "\n",
    "1. **Training set (`split=0`):** The tweets for which we have noisy, conflicting crowd labels; we will resolve these conflicts using the `GenerativeModel` and then use them as training data for the LSTM\n",
    "\n",
    "2. **Test set (`split=1`):** We will pretend that we do not have any crowd labels for this split of the data, and use these to test the LSTM's performance on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import Context, Candidate\n",
    "from snorkel.contrib.models.text import RawText\n",
    "\n",
    "# Make sure DB is cleared\n",
    "session.query(Context).delete()\n",
    "session.query(Candidate).delete()\n",
    "\n",
    "# Now we create the candidates with a simple loop\n",
    "tweet_bodies = candidate_labeled_tweets \\\n",
    "    [[\"tweet_id\", \"tweet_body\"]] \\\n",
    "    .sort_values(\"tweet_id\") \\\n",
    "    .drop_duplicates()\n",
    "\n",
    "# Generate and store the tweet candidates to be classified\n",
    "# Note: We split the tweets in two sets: one for which the crowd \n",
    "# labels are not available to Snorkel (test, 10%) and one for which we assume\n",
    "# crowd labels are obtained (to be used for training, 90%)\n",
    "total_tweets = len(tweet_bodies)\n",
    "tweet_list = []\n",
    "test_split = total_tweets*0.1\n",
    "for i, t in tweet_bodies.iterrows():\n",
    "    split = 1 if i <= test_split else 0\n",
    "    raw_text = RawText(stable_id=t.tweet_id, name=t.tweet_id, text=t.tweet_body)\n",
    "    tweet = Tweet(tweet=raw_text, split=split)\n",
    "    tweet_list.append(tweet)\n",
    "    session.add(tweet)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Labels`\n",
    "\n",
    "Next, we'll store the labels for each of the training candidates in a sparse matrix (which will also automatically be saved to the Snorkel database), with one row for each candidate and one column for each crowd worker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/629 [00:00<00:04, 135.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 629/629 [00:02<00:00, 218.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.92 s, sys: 12 ms, total: 2.93 s\n",
      "Wall time: 2.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<629x102 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12580 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "from collections import defaultdict\n",
    "\n",
    "# Extract worker votes\n",
    "# Cache locally to speed up for this small set\n",
    "worker_labels = candidate_labeled_tweets[[\"tweet_id\", \"worker_id\", \"emotion\"]]\n",
    "wls = defaultdict(list)\n",
    "for i, row in worker_labels.iterrows():\n",
    "    wls[str(row.tweet_id)].append((str(row.worker_id), row.emotion))\n",
    "    \n",
    "\n",
    "# Create a label generator\n",
    "def worker_label_generator(t):\n",
    "    \"\"\"A generator over the different (worker_id, label_id) pairs for a Tweet.\"\"\"\n",
    "    for worker_id, label in wls[t.tweet.name]:\n",
    "        yield worker_id, label\n",
    "        \n",
    "labeler = LabelAnnotator(label_generator=worker_label_generator)\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we load the ground truth (\"gold\") labels for both the training and test sets, and store as numpy arrays\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_labels = defaultdict(list)\n",
    "\n",
    "# Get gold labels in verbose form\n",
    "verbose_labels = dict([(str(t.tweet_id), t.sentiment) \n",
    "                       for i, t in gold_answers[[\"tweet_id\", \"sentiment\"]].iterrows()])\n",
    "\n",
    "# Iterate over splits, align with Candidate ordering\n",
    "for split in range(2):\n",
    "    cands = session.query(Tweet).filter(Tweet.split == split).order_by(Tweet.id).all() \n",
    "    for c in cands:\n",
    "        # Think this is just an odd way of label encoding between 1 and 5?\n",
    "        gold_labels[split].append(values.index(verbose_labels[c.tweet.name]) + 1) \n",
    "        \n",
    "train_cand_labels = np.array(gold_labels[0])\n",
    "test_cand_labels = np.array(gold_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Resolving Crowd Conflicts with the Generative Model\n",
    "\n",
    "Until now we have converted the raw crowdsourced data into a labeling matrix that can be provided as input to `Snorkel`. We will now show how to:\n",
    "\n",
    "1. Use `Snorkel's` generative model to learn the accuracy of each crowd contributor.\n",
    "2. Use the learned model to estimate a marginal distribution over the domain of possible labels for each task.\n",
    "3. Use the estimated marginal distribution to obtain the maximum a posteriori probability estimate for the label that each task takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from snorkel.learning.gen_learning import GenerativeModel\n",
    "\n",
    "# Initialize Snorkel's generative model for\n",
    "# learning the different worker accuracies.\n",
    "gen_model = GenerativeModel(lf_propensity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 5\n"
     ]
    }
   ],
   "source": [
    "# Train the generative model\n",
    "gen_model.train(\n",
    "    L_train,\n",
    "    reg_type=2,\n",
    "    reg_param=0.1,\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infering the MAP assignment for each task\n",
    "Each task corresponds to an independent random variable. Thus, we can simply associate each task with the most probably label based on the estimated marginal distribution and get an accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9952305246\n"
     ]
    }
   ],
   "source": [
    "accuracy = gen_model.score(L_train, train_cand_labels)\n",
    "print(\"Accuracy: {:.10f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority vote\n",
    "\n",
    "It seems like we did well- but how well?  Given that this is a fairly simple task--we have 20 contributors per tweet (and most of them are far better than random)--**we expect majority voting to perform extremely well**, so we can check against majority vote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9841017488076311\n",
      "Number incorrect:10\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Collect the majority vote answer for each tweet\n",
    "mv = []\n",
    "for i in range(L_train.shape[0]):\n",
    "    c = Counter([L_train[i,j] for j in L_train[i].nonzero()[1]])\n",
    "    mv.append(c.most_common(1)[0][0])\n",
    "mv = np.array(mv)\n",
    "\n",
    "# Count the number correct by majority vote\n",
    "n_correct = np.sum([1 for i in range(L_train.shape[0]) if mv[i] == train_cand_labels[i]])\n",
    "print (\"Accuracy:{}\".format(n_correct / float(L_train.shape[0])))\n",
    "print (\"Number incorrect:{}\".format(L_train.shape[0] - n_correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that while majority vote makes 10 errors, the Snorkel model makes only 3!  What about an average crowd worker?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average human accuracy\n",
    "\n",
    "We see that the average accuracy of a single crowd worker is in fact much lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:0.729664764868133\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for j in range(L_train.shape[1]):\n",
    "    n_correct = np.sum([1 for i in range(L_train.shape[0]) if L_train[i,j] == train_cand_labels[i]])\n",
    "    acc = n_correct / float(L_train[:,j].nnz)\n",
    "    accs.append(acc)\n",
    "print( \"Mean Accuracy:{}\".format( np.mean(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet(Raw Text I dunno which asshole in the sky flunked out of weather school or whatever but I should not need a jacket in May)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cands = session.query(Tweet).filter(Tweet.split == 0).order_by(Tweet.id).all()\n",
    "train_cands[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training an ML Model with Snorkel for Sentiment Analysis over Unseen Tweets\n",
    "\n",
    "In the previous step, we saw that Snorkel's generative model can help to denoise crowd labels automatically. However, what happens when we don't have noisy crowd labels for a tweet?\n",
    "\n",
    "In this step, we'll use the estimates of the generative model as _probabilistic training labels_ to train a simple LSTM sentiment analysis model, which takes as input a tweet **for which no crowd labels are available** and predicts its sentiment.\n",
    "\n",
    "First, we get the probabilistic training labels (_training marginals_) which are just the marginal estimates of the generative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 629 marginals\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll train a simple LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.tensorflow import TextRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/snorkel/learning/tensorflow/rnn/rnn_base.py:36: UserWarning: Candidate 618 has argument past max length for model:\t[arg ends at index 28; max len 28]\n",
      "  warnings.warn('\\t'.join([w.format(i), info]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "WARNING:tensorflow:From /dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/snorkel/learning/tensorflow/noise_aware_model.py:77: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextRNN] Training model\n",
      "[TextRNN] n_train=629  #epochs=200  batch size=256\n",
      "[TextRNN] Epoch 0 (1.05s)\tAverage loss=1.547467\n",
      "[TextRNN] Epoch 5 (2.06s)\tAverage loss=0.177643\n",
      "[TextRNN] Epoch 10 (3.15s)\tAverage loss=0.050926\n",
      "[TextRNN] Epoch 15 (4.16s)\tAverage loss=0.051957\n",
      "[TextRNN] Epoch 20 (5.14s)\tAverage loss=0.027945\n",
      "[TextRNN] Epoch 25 (6.11s)\tAverage loss=0.025162\n",
      "[TextRNN] Epoch 30 (7.07s)\tAverage loss=0.026350\n",
      "[TextRNN] Epoch 35 (8.03s)\tAverage loss=0.037287\n",
      "[TextRNN] Epoch 40 (8.95s)\tAverage loss=0.026180\n",
      "[TextRNN] Epoch 45 (9.89s)\tAverage loss=0.028730\n",
      "[TextRNN] Epoch 50 (10.80s)\tAverage loss=0.023424\n",
      "[TextRNN] Epoch 55 (11.76s)\tAverage loss=0.023584\n",
      "[TextRNN] Epoch 60 (12.70s)\tAverage loss=0.021186\n",
      "[TextRNN] Epoch 65 (13.68s)\tAverage loss=0.028317\n",
      "[TextRNN] Epoch 70 (14.62s)\tAverage loss=0.021332\n",
      "[TextRNN] Epoch 75 (15.65s)\tAverage loss=0.020816\n",
      "[TextRNN] Epoch 80 (16.63s)\tAverage loss=0.020187\n",
      "[TextRNN] Epoch 85 (17.56s)\tAverage loss=0.020813\n",
      "[TextRNN] Epoch 90 (18.49s)\tAverage loss=0.034834\n",
      "[TextRNN] Epoch 95 (19.49s)\tAverage loss=0.019741\n",
      "[TextRNN] Epoch 100 (20.49s)\tAverage loss=0.038676\n",
      "[TextRNN] Epoch 105 (21.50s)\tAverage loss=0.025656\n",
      "[TextRNN] Epoch 110 (22.48s)\tAverage loss=0.034486\n",
      "[TextRNN] Epoch 115 (23.43s)\tAverage loss=0.021657\n",
      "[TextRNN] Epoch 120 (24.31s)\tAverage loss=0.021864\n",
      "[TextRNN] Epoch 125 (25.24s)\tAverage loss=0.018930\n",
      "[TextRNN] Epoch 130 (26.20s)\tAverage loss=0.019719\n",
      "[TextRNN] Epoch 135 (27.15s)\tAverage loss=0.020109\n",
      "[TextRNN] Epoch 140 (28.11s)\tAverage loss=0.019114\n",
      "[TextRNN] Epoch 145 (29.10s)\tAverage loss=0.018110\n",
      "[TextRNN] Epoch 150 (30.09s)\tAverage loss=0.019963\n",
      "[TextRNN] Epoch 155 (31.03s)\tAverage loss=0.018345\n",
      "[TextRNN] Epoch 160 (31.99s)\tAverage loss=0.020997\n",
      "[TextRNN] Epoch 165 (32.97s)\tAverage loss=0.019281\n",
      "[TextRNN] Epoch 170 (33.84s)\tAverage loss=0.019457\n",
      "[TextRNN] Epoch 175 (34.78s)\tAverage loss=0.017222\n",
      "[TextRNN] Epoch 180 (35.77s)\tAverage loss=0.020338\n",
      "[TextRNN] Epoch 185 (36.76s)\tAverage loss=0.020534\n",
      "[TextRNN] Epoch 190 (37.72s)\tAverage loss=0.019646\n",
      "[TextRNN] Epoch 195 (38.69s)\tAverage loss=0.020606\n",
      "[TextRNN] Epoch 199 (39.46s)\tAverage loss=0.015863\n",
      "[TextRNN] Training done (39.46s)\n"
     ]
    }
   ],
   "source": [
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        100,\n",
    "    'n_epochs':   200,\n",
    "    'dropout':    0.2,\n",
    "    'print_freq': 5\n",
    "}\n",
    "\n",
    "lstm = TextRNN(seed=1701, cardinality=Tweet.cardinality)\n",
    "train_cands = session.query(Tweet).filter(Tweet.split == 0).order_by(Tweet.id).all()\n",
    "lstm.train(train_cands, train_marginals, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666667\n"
     ]
    }
   ],
   "source": [
    "test_cands = session.query(Tweet).filter(Tweet.split == 1).order_by(Tweet.id).all()\n",
    "accuracy = lstm.score(test_cands, test_cand_labels)\n",
    "print(\"Accuracy: {:.10f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we're already close to the accuracy of an average crowd worker! If we wanted to improve the score, we could tune the LSTM model using grid search (see the Intro tutorial), use [pre-trained word embeddings](https://nlp.stanford.edu/projects/glove/), or many other common techniques for getting state-of-the-art scores. Notably, we're doing this without using gold labels, but rather noisy crowd-labels!\n",
    "\n",
    "For more, checkout the other tutorials!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
